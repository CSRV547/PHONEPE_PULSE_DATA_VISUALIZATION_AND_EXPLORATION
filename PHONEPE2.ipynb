{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GIT CLONING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloned repository to C:\\VS PROJECTS\\PHONEPE PROJ\\DATA\n"
     ]
    }
   ],
   "source": [
    "import git\n",
    "\n",
    "repo_url = \"https://github.com/PhonePe/pulse.git\"\n",
    "\n",
    "destination_dir = r\"C:\\VS PROJECTS\\PHONEPE PROJ\\DATA\"\n",
    "\n",
    "repo = git.Repo.clone_from(repo_url, destination_dir)\n",
    "\n",
    "print(f\"Cloned repository to {destination_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONVERTING JSON FILES INTO DATAFRAME TO MIGRATE THE DATA INTO SQL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------- Importing required packages for conversion -------------------------------#\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "#----------------------------- Establishing connection with MySQL to migrate the data ----------------------#\n",
    "\n",
    "mycon = mysql.connector.connect(host=\"127.0.0.1\",user=\"root\",password=\"<Your MySQL Password>\")\n",
    "mycursor = mycon.cursor()\n",
    "mycursor.execute(f\"CREATE DATABASE IF NOT EXISTS Phonepe;\")\n",
    "\n",
    "\n",
    "root=f'/'#formatting to path conversion\n",
    "\n",
    "#-------------------------------------- Data Conversion and Migration ----------------------------------------#\n",
    "\n",
    "#creating a list of columns for specific dataframe\n",
    "clm={'State':[], 'Year':[],'Quarter':[],'Transaction_type':[], 'Transaction_count':[], 'Transaction_amount':[]}\n",
    "\n",
    "#path of concerned file\n",
    "agg_path=r\"<Location of the file in your machine>/data/aggregated/transaction/country/india/state/\"\n",
    "agg_state=os.listdir(agg_path)\n",
    "\n",
    "#block of code to access the concerned file and converting into dataframe\n",
    "for i in agg_state:\n",
    "    p_i=agg_path+i+root\n",
    "    Agg_yr=os.listdir(p_i)\n",
    "    for j in Agg_yr:\n",
    "        p_j=p_i+j+root\n",
    "        Agg_yr_list=os.listdir(p_j)\n",
    "        for k in Agg_yr_list:\n",
    "            p_k=p_j+k\n",
    "            Data=open(p_k,'r')\n",
    "            D=json.load(Data)\n",
    "            for z in D['data']['transactionData']:\n",
    "              Name=z['name']\n",
    "              count=z['paymentInstruments'][0]['count']\n",
    "              amount=z['paymentInstruments'][0]['amount']\n",
    "              clm['Transaction_type'].append(Name)\n",
    "              clm['Transaction_count'].append(count)\n",
    "              clm['Transaction_amount'].append(amount)\n",
    "              clm['State'].append(i)\n",
    "              clm['Year'].append(j)\n",
    "              clm['Quarter'].append(int(k.strip('.json')))\n",
    "\n",
    "Agg_Trans=pd.DataFrame(clm)\n",
    "\n",
    "#lines of code to replace Nan values with respective suitable values\n",
    "Agg_Trans= Agg_Trans.fillna({\n",
    "        'Transaction_type': \"Undefined\",\n",
    "        'Transaction_count': 0,\n",
    "        'Transaction_amount': 0\n",
    "    })\n",
    "\n",
    "#creating engine to migrate the data into sql\n",
    "engine = create_engine('mysql+mysqlconnector://root:<Your MySQL Password>@localhost/Phonepe', echo=False)\n",
    "Agg_Trans.to_sql('agg_trans', con=engine, if_exists='replace', index=False)\n",
    "engine.dispose()\n",
    "\n",
    "#path of concerned file\n",
    "map_path=(r\"<Location of the file in your machine>/data/map/transaction/hover/country/india/state/\")\n",
    "map_state=os.listdir(map_path)\n",
    "\n",
    "#block of code to access the concerned file and converting into dataframe\n",
    "for i in map_state:\n",
    "    p_i=map_path+i+root\n",
    "    Agg_yr=os.listdir(p_i)\n",
    "    for j in Agg_yr:\n",
    "        p_j=p_i+j+root\n",
    "        Agg_yr_list=os.listdir(p_j)\n",
    "        for k in Agg_yr_list:\n",
    "            p_k=p_j+k\n",
    "            Data=open(p_k,'r')\n",
    "            D=json.load(Data)\n",
    "            for z in D['data']['hoverDataList']:\n",
    "              Name=z['name']\n",
    "              count=z['metric'][0]['count']\n",
    "              amount=z['metric'][0]['amount']\n",
    "              clm['Transaction_type'].append(Name)\n",
    "              clm['Transaction_count'].append(count)\n",
    "              clm['Transaction_amount'].append(amount)\n",
    "              clm['State'].append(i)\n",
    "              clm['Year'].append(j)\n",
    "              clm['Quarter'].append(int(k.strip('.json')))\n",
    "                \n",
    "Map_Trans=pd.DataFrame(clm)\n",
    "\n",
    "#lines of code to replace Nan values with respective suitable values\n",
    "Map_Trans= Map_Trans.fillna({\n",
    "        'Transaction_type': \"Undefined\",\n",
    "        'Transaction_count': 0,\n",
    "        'Transaction_amount': 0\n",
    "    })\n",
    "\n",
    "#creating engine to migrate the data into sql\n",
    "engine = create_engine('mysql+mysqlconnector://root:<Your MySQL Password>@localhost/Phonepe', echo=False)\n",
    "Map_Trans.to_sql('map_trans', con=engine, if_exists='replace', index=False)\n",
    "engine.dispose()\n",
    "\n",
    "\n",
    "\n",
    "#creating a list of columns for specific dataframe\n",
    "clm={'State':[], 'Year':[],'Quarter':[],'District':[], 'Transaction_count':[], 'Transaction_amount':[]}\n",
    "\n",
    "#path of concerned file\n",
    "top_path=r\"<Location of the file in your machine>/data/top/transaction/country/india/state/\"\n",
    "top_state=os.listdir(top_path)\n",
    "\n",
    "#block of code to access the concerned file and converting into dataframe\n",
    "for i in top_state:\n",
    "    p_i=top_path+i+root\n",
    "    Agg_yr=os.listdir(p_i)\n",
    "    for j in Agg_yr:\n",
    "        p_j=p_i+j+root\n",
    "        Agg_yr_list=os.listdir(p_j)\n",
    "        for k in Agg_yr_list:\n",
    "            p_k=p_j+k\n",
    "            Data=open(p_k,'r')\n",
    "            D=json.load(Data)\n",
    "            for z in D['data']['districts']:\n",
    "              Name=z['entityName']\n",
    "              count=z['metric']['count']\n",
    "              amount=z['metric']['amount']\n",
    "              clm['District'].append(Name)\n",
    "              clm['Transaction_count'].append(count)\n",
    "              clm['Transaction_amount'].append(amount)\n",
    "              clm['State'].append(i)\n",
    "              clm['Year'].append(j)\n",
    "              clm['Quarter'].append(int(k.strip('.json')))\n",
    "     \n",
    "Top_Trans_dist=pd.DataFrame(clm)\n",
    "\n",
    "#lines of code to replace Nan values with respective suitable values\n",
    "Top_Trans_dist= Top_Trans_dist.fillna({\n",
    "        'District': \"Undefined\",\n",
    "        'Transaction_count': 0,\n",
    "        'Transaction_amount': 0\n",
    "    })\n",
    "\n",
    "#creating engine to migrate the data into sql\n",
    "engine = create_engine('mysql+mysqlconnector://root:<Your MySQL Password>@localhost/Phonepe', echo=False)\n",
    "Top_Trans_dist.to_sql('top_trans_dist', con=engine, if_exists='replace', index=False)\n",
    "engine.dispose()\n",
    "\n",
    "\n",
    "#creating a list of columns for specific dataframe\n",
    "clm={'State':[], 'Year':[],'Quarter':[],'Pincode':[], 'Transaction_count':[], 'Transaction_amount':[]}\n",
    "\n",
    "#block of code to access the concerned file and converting into dataframe\n",
    "for i in top_state:\n",
    "    p_i=top_path+i+root\n",
    "    Agg_yr=os.listdir(p_i)\n",
    "    for j in Agg_yr:\n",
    "        p_j=p_i+j+root\n",
    "        Agg_yr_list=os.listdir(p_j)\n",
    "        for k in Agg_yr_list:\n",
    "            p_k=p_j+k\n",
    "            Data=open(p_k,'r')\n",
    "            D=json.load(Data)\n",
    "            for y in D['data']['pincodes']:\n",
    "                Name=y['entityName']\n",
    "                count=y['metric']['count']\n",
    "                amount=y['metric']['amount']\n",
    "                clm['Pincode'].append(Name)\n",
    "                clm['Transaction_count'].append(count)\n",
    "                clm['Transaction_amount'].append(amount)\n",
    "                clm['State'].append(i)\n",
    "                clm['Year'].append(j)\n",
    "                clm['Quarter'].append(int(k.strip('.json')))\n",
    "Top_Trans_pin=pd.DataFrame(clm)\n",
    "\n",
    "#lines of code to replace Nan values with respective suitable values\n",
    "Top_Trans_pin= Top_Trans_pin.fillna({\n",
    "        'Pincode': \"Undefined\",\n",
    "        'Transaction_count': 0,\n",
    "        'Transaction_amount': 0\n",
    "    })\n",
    "\n",
    "#creating engine to migrate the data into sql\n",
    "engine = create_engine('mysql+mysqlconnector://root:<Your MySQL Password>@localhost/Phonepe', echo=False)\n",
    "Top_Trans_pin.to_sql('top_trans_pin', con=engine, if_exists='replace', index=False)\n",
    "engine.dispose()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#creating a list of columns for specific dataframe\n",
    "clm1={'State':[], 'Year':[],'Quarter':[],'Pincode':[], 'Registered_Users':[]}\n",
    "clm2={'State':[], 'Year':[],'Quarter':[],'District':[], 'Registered_Users':[]}\n",
    "\n",
    "#path of concerned file\n",
    "top_path_user=r\"<Location of the file in your machine>/data/top/user/country/india/state/\"\n",
    "top_state_user=os.listdir(top_path_user)\n",
    "\n",
    "#block of code to access the concerned file and converting into dataframe\n",
    "for i in top_state_user:\n",
    "    p_i=top_path_user+i+root\n",
    "    Agg_yr=os.listdir(p_i)\n",
    "    for j in Agg_yr:\n",
    "        p_j=p_i+j+root\n",
    "        Agg_yr_list=os.listdir(p_j)\n",
    "        for k in Agg_yr_list:\n",
    "            p_k=p_j+k\n",
    "            Data=open(p_k,'r')\n",
    "            D=json.load(Data)\n",
    "            for y in D['data']['pincodes']:\n",
    "                Name=y['name']\n",
    "                count=y['registeredUsers']\n",
    "                clm1['Pincode'].append(Name)\n",
    "                clm1['Registered_Users'].append(count)\n",
    "                clm1['State'].append(i)\n",
    "                clm1['Year'].append(j)\n",
    "                clm1['Quarter'].append(int(k.strip('.json')))\n",
    "            for y in D['data']['districts']:\n",
    "                Name=y['name']\n",
    "                count=y['registeredUsers']\n",
    "                clm2['District'].append(Name)\n",
    "                clm2['Registered_Users'].append(count)\n",
    "                clm2['State'].append(i)\n",
    "                clm2['Year'].append(j)\n",
    "                clm2['Quarter'].append(int(k.strip('.json')))\n",
    "Top_user_pin=pd.DataFrame(clm1)\n",
    "\n",
    "#lines of code to replace Nan values with respective suitable values\n",
    "Top_user_pin= Top_user_pin.fillna({\n",
    "        'Pincode': \"Undefined\",\n",
    "        'Registered_Users': 0\n",
    "    })\n",
    "\n",
    "#creating engine to migrate the data into sql\n",
    "engine = create_engine('mysql+mysqlconnector://root:<Your MySQL Password>@localhost/Phonepe', echo=False)\n",
    "Top_user_pin.to_sql('top_user_pin', con=engine, if_exists='replace', index=False)\n",
    "engine.dispose()\n",
    "\n",
    "Top_user_dis=pd.DataFrame(clm2)\n",
    "\n",
    "#lines of code to replace Nan values with respective suitable values\n",
    "Top_user_dis= Top_user_dis.fillna({\n",
    "        'District': \"Undefined\",\n",
    "        'Registered_Users': 0\n",
    "    })\n",
    "\n",
    "#creating engine to migrate the data into sql\n",
    "engine = create_engine('mysql+mysqlconnector://root:<Your MySQL Password>@localhost/Phonepe', echo=False)\n",
    "Top_user_dis.to_sql('top_user_dis', con=engine, if_exists='replace', index=False)\n",
    "engine.dispose()\n",
    "\n",
    "\n",
    "\n",
    "#creating a list of columns for specific dataframe\n",
    "clm={'State':[], 'Year':[],'Quarter':[],'Brand':[], 'Users_Count':[],'User_Percentage':[],'Registered_Users':[],'AppOpen':[]}\n",
    "\n",
    "#path of concerned file\n",
    "agg_path_user=r\"<Location of the file in your machine>/data/aggregated/user/country/india/state/\"\n",
    "agg_state_user=os.listdir(agg_path_user)\n",
    "\n",
    "#block of code to access the concerned file and converting into dataframe\n",
    "for i in agg_state_user:\n",
    "    p_i=agg_path_user+i+root\n",
    "    Agg_yr=os.listdir(p_i)\n",
    "    for j in Agg_yr:\n",
    "        p_j=p_i+j+root\n",
    "        Agg_yr_list=os.listdir(p_j)\n",
    "        for k in Agg_yr_list:\n",
    "            p_k=p_j+k\n",
    "            Data=open(p_k,'r')\n",
    "            D=json.load(Data)\n",
    "            if D['data']['usersByDevice'] is not None:\n",
    "                for y in D['data']['usersByDevice']:\n",
    "                    Name=y['brand']\n",
    "                    count=y['count']\n",
    "                    per=y['percentage']\n",
    "                    clm['Brand'].append(Name)\n",
    "                    clm['Users_Count'].append(count)\n",
    "                    clm['User_Percentage'].append(per)\n",
    "                    clm['State'].append(i)\n",
    "                    clm['Year'].append(j)\n",
    "                    clm['Quarter'].append(int(k.strip('.json')))\n",
    "                    clm['Registered_Users'].append(D['data']['aggregated']['registeredUsers'])\n",
    "                    clm['AppOpen'].append(D['data']['aggregated']['appOpens'])\n",
    "            else:\n",
    "                Reg=D['data']['aggregated']['registeredUsers']\n",
    "                count=D['data']['aggregated']['appOpens']\n",
    "                clm['Registered_Users'].append(Reg)\n",
    "                clm['AppOpen'].append(count)\n",
    "                clm['State'].append(i)\n",
    "                clm['Year'].append(j)\n",
    "                clm['Quarter'].append(int(k.strip('.json')))\n",
    "                clm['Brand'].append(None)\n",
    "                clm['Users_Count'].append(None)\n",
    "                clm['User_Percentage'].append(None)\n",
    "agg_user=pd.DataFrame(clm)\n",
    "\n",
    "#lines of code to replace Nan values with respective suitable values\n",
    "agg_user= agg_user.fillna({\n",
    "        'Brand': \"Undefined\",\n",
    "        'Registered_Users': 0,\n",
    "        'Users_Count':0,\n",
    "        'User_Percentage':0,\n",
    "        'AppOpen':0\n",
    "    })\n",
    "\n",
    "#creating engine to migrate the data into sql\n",
    "engine = create_engine('mysql+mysqlconnector://root:<Your MySQL Password>@localhost/Phonepe', echo=False)\n",
    "agg_user.to_sql('agg_user', con=engine, if_exists='replace', index=False)\n",
    "engine.dispose()\n",
    "\n",
    "\n",
    "\n",
    "#creating a list of columns for specific dataframe\n",
    "clm={'State':[], 'Year':[],'Quarter':[],'Registered_Users':[],'AppOpen':[],'District':[]}\n",
    "\n",
    "#path of concerned file\n",
    "map_path_user=r\"<Location of the file in your machine>/data/map/user/hover/country/india/state/\"\n",
    "map_state_user=os.listdir(map_path_user)\n",
    "\n",
    "#block of code to access the concerned file and converting into dataframe\n",
    "for i in map_state_user:\n",
    "    p_i=map_path_user+i+root\n",
    "    Agg_yr=os.listdir(p_i)\n",
    "    for j in Agg_yr:\n",
    "        p_j=p_i+j+root\n",
    "        Agg_yr_list=os.listdir(p_j)\n",
    "        for k in Agg_yr_list:\n",
    "            p_k=p_j+k\n",
    "            Data=open(p_k,'r')\n",
    "            D=json.load(Data)\n",
    "            for dist,data in D['data']['hoverData'].items():\n",
    "                Name=data['registeredUsers']\n",
    "                count=data['appOpens']\n",
    "                clm['District'].append(dist)\n",
    "                clm['Registered_Users'].append(Name)\n",
    "                clm['AppOpen'].append(count)\n",
    "                clm['State'].append(i)\n",
    "                clm['Year'].append(j)\n",
    "                clm['Quarter'].append(int(k.strip('.json')))\n",
    "map_user=pd.DataFrame(clm)\n",
    "\n",
    "#lines of code to replace Nan values with respective suitable values\n",
    "map_user= map_user.fillna({\n",
    "        'Registered_Users': 0,\n",
    "        'AppOpen':0,\n",
    "        'District':\"Undefined\"\n",
    "    })\n",
    "\n",
    "#creating engine to migrate the data into sql\n",
    "engine = create_engine('mysql+mysqlconnector://root:<Your MySQL Password>@localhost/Phonepe', echo=False)\n",
    "map_user.to_sql('map_user', con=engine, if_exists='replace', index=False)\n",
    "engine.dispose()\n",
    "\n",
    "\n",
    "comb_df=pd.concat([Agg_Trans,Map_Trans,Top_Trans_dist,Top_Trans_pin,Top_user_pin,Top_user_dis,agg_user,map_user])\n",
    "comb_df= comb_df.fillna({\n",
    "        'Registered_Users': 0,\n",
    "        'AppOpen':0,\n",
    "        'District':\"Undefined\",\n",
    "        'Transacion_type':\"Undefined\",\n",
    "        'Transacion_count':0,\n",
    "        'Transacion_amount':0,\n",
    "        'Brand':\"Undefined\",\n",
    "        'Pincode':\"Undefined\",\n",
    "        'Users_Count':0,\n",
    "        'User_Percentage':0\n",
    "    })\n",
    "\n",
    "#creating engine to migrate the data into sql\n",
    "engine = create_engine('mysql+mysqlconnector://root:<Your MySQL Password>@localhost/Phonepe', echo=False)\n",
    "comb_df.to_sql('comb_df', con=engine, if_exists='replace', index=False)\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATA VISUALIZATION IN STREAMLIT APPLICATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------- Importing Required Packages ---------------------------------#\n",
    "import streamlit as st\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import mysql.connector\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)  # to neglect warnings thats not serious\n",
    "\n",
    "# ----------------------------- Establishing connection to MySQL to fetch the stored data -------------#\n",
    "mycon = mysql.connector.connect(host=\"127.0.0.1\", user=\"root\", password=\"<Your MySQL Password>\")\n",
    "mycursor = mycon.cursor()\n",
    "\n",
    "# ------------------------------------ Streamlit Application Setup -----------------------------------#\n",
    "st.set_page_config(page_title=\"PhonePe Data API\", page_icon=':money_with_wings:', layout='wide')\n",
    "nav = st.sidebar.radio(\"Navigation panel\",['HOME','About Page'])\n",
    "\n",
    "if nav=='HOME':\n",
    "    st.title(\":chart: PhonePe Data Visualisation\")\n",
    "    col1, col2 = st.columns([2, 1])\n",
    "\n",
    "    with col1:\n",
    "        st.subheader(\"Select year\")\n",
    "        year = st.selectbox(\"Select a year range\", [2018, 2019, 2020, 2021, 2022, 2023])\n",
    "\n",
    "    with col2:\n",
    "        st.subheader(\"Select Quarter\")\n",
    "        abd = st.selectbox(\"Dropdown\", [1, 2, 3, 4])\n",
    "\n",
    "    year = int(year)\n",
    "    quarter = int(abd)\n",
    "\n",
    "    # Displaying Error when 2023-Q4\n",
    "    if year == 2023 and quarter == 4:\n",
    "        st.error(\"NO DATA AVAILABLE TO DISPLAY FOR 4th QUARTER OF 2023\")\n",
    "    else:\n",
    "        # creating a list of state names\n",
    "        stt = f\"SELECT DISTINCT State FROM phonepe.map_trans\"\n",
    "        state_df = pd.read_sql(stt, con=mycon)\n",
    "        state_list = state_df['State'].tolist()\n",
    "        # creating tabs for visually appealing with whereas data visualization\n",
    "        tab1, tab2, tab3, tab4, tab5 = st.tabs(\n",
    "            ['StateWise Analysis', 'DistrictWise Analysis', 'PinCodeWise Analysis', 'CategoryWise Analysis',\n",
    "             'NationWide Analysis'])\n",
    "\n",
    "        with tab1:  # when switched for 1st Tab\n",
    "            x = st.selectbox(\"Select STATE\", state_list, key='sb1')  # let user to select state from list of states\n",
    "            Trans_val_state = []  # creating a empty list to store the transaction values\n",
    "            Recharge_query = f\"SELECT DISTINCT * FROM phonepe.agg_trans WHERE State = '{x}' AND Year = '{year}' AND Quarter ='{quarter}' AND Transaction_type = 'Recharge & bill payments';\"\n",
    "            Rec_df = pd.read_sql(Recharge_query, con=mycon)\n",
    "            Rec_list = Rec_df.values.tolist()\n",
    "            Trans_val_state.append(\n",
    "                Rec_list[0][5] if len(Rec_list) != 0 else 0)  # returns total amount accounted on recharge\n",
    "            peer_query = f\"SELECT DISTINCT * FROM phonepe.agg_trans WHERE State = '{x}' AND Year = '{year}' AND Quarter ='{quarter}' AND Transaction_type = 'Peer-to-peer payments';\"\n",
    "            peer_df = pd.read_sql(peer_query, con=mycon)\n",
    "            peer_list = peer_df.values.tolist()\n",
    "            Trans_val_state.append(\n",
    "                peer_list[0][5] if len(peer_list) != 0 else 0)  # returns total amount accounted on peer transfer\n",
    "            Merch_query = f\"SELECT DISTINCT * FROM phonepe.agg_trans WHERE State = '{x}' AND Year = '{year}' AND Quarter ='{quarter}' AND Transaction_type ='Merchant payments';\"\n",
    "            Merch_df = pd.read_sql(Merch_query, con=mycon)\n",
    "            Merch_list = Merch_df.values.tolist()\n",
    "            Trans_val_state.append(\n",
    "                Merch_list[0][5] if len(Merch_list) != 0 else 0)  # returns total amount accounted on merchant payments\n",
    "            fin_query = f\"SELECT DISTINCT * FROM phonepe.agg_trans WHERE State = '{x}' AND Year = '{year}' AND Quarter ='{quarter}' AND Transaction_type ='Financial Services';\"\n",
    "            fin_df = pd.read_sql(fin_query, con=mycon)\n",
    "            fin_list = fin_df.values.tolist()\n",
    "            Trans_val_state.append(fin_list[0][5] if len(fin_list) != 0 else 0)  # returns total amount accounted on finance\n",
    "            oth_query = f\"SELECT DISTINCT * FROM phonepe.agg_trans WHERE State = '{x}' AND Year = '{year}' AND Quarter ='{quarter}' AND Transaction_type ='Others';\"\n",
    "            oth_df = pd.read_sql(oth_query, con=mycon)\n",
    "            oth_list = oth_df.values.tolist()\n",
    "            Trans_val_state.append(\n",
    "                oth_list[0][5] if len(oth_list) != 0 else 0)  # returns total amount accounted on other categories\n",
    "            brand_query = f\"SELECT DISTINCT Brand FROM phonepe.agg_user WHERE State='{x}' AND Year= '{year}' AND Quarter ='{quarter}'\"\n",
    "            brand_df = pd.read_sql(brand_query, con=mycon)\n",
    "            brand_list = brand_df['Brand'].tolist()  # returns a list of brand name\n",
    "            brand_count_list = []  # creating a empty list to store users of concerned brand\n",
    "            for c in brand_list:\n",
    "                brand_count_query = f\"SELECT DISTINCT * FROM phonepe.agg_user WHERE State = '{x}' AND Year = '{year}' AND Quarter ='{quarter}' AND Brand = '{c}';\"\n",
    "                brand_count_df = pd.read_sql(brand_count_query, con=mycon)\n",
    "                brand_count_lists = brand_count_df.values.tolist()\n",
    "                brand_count_list.append(brand_count_lists[0][4] if len(\n",
    "                    brand_count_lists) != 0 else 0)  # returns total users with respect to the brand\n",
    "\n",
    "            col41, col42 = st.columns(2)  # diving the page into two equal sections\n",
    "            with col41:  # with first half section\n",
    "                category = ['Recharge & Bill Payments', 'Peer to Peer Payments', 'Merchant Payments', 'Financial Services',\n",
    "                            'Others']  # list of title\n",
    "                cols = ['#4C8BE2', '#00e061', '#fe073a', '#e1bc3a', '#4e8e71']  # list of color code for pie visualization\n",
    "                exp = [1.5, 0.02, 0.9, 0.01, 1.2]  # list of spacing in pie\n",
    "                # block of code to create a pie chart\n",
    "                plt.pie(Trans_val_state, labels=category,\n",
    "                        textprops=dict(size=20, color='black'),\n",
    "                        radius=3,\n",
    "                        colors=cols,\n",
    "                        autopct='%2.2f%%',\n",
    "                        explode=exp,\n",
    "                        shadow=True,\n",
    "                        startangle=45)\n",
    "                plt.title('Transaction Type\\n\\n\\n\\n\\n', color='#ed0000', size=50)\n",
    "                st.pyplot(plt)\n",
    "            with col42:  # with second half section\n",
    "                if brand_list[0]!='Undefined':\n",
    "                    # block of code to create a bar chart\n",
    "                    plt.figure(figsize=(8, 6))\n",
    "                    plt.bar(brand_list, brand_count_list, color=\"blue\")\n",
    "                    plt.xticks(rotation=90)\n",
    "                    plt.xlabel('Brand')\n",
    "                    plt.ylabel('UserCount')\n",
    "                    plt.title('Bar Plot Example')\n",
    "                    for i, j in zip(brand_list, brand_count_list):\n",
    "                        plt.annotate(str(int(j)),\n",
    "                                     xy=(i, j + 3),\n",
    "                                     color='black',\n",
    "                                     size='7')\n",
    "                    st.pyplot(plt)\n",
    "                else:\n",
    "                    st.info(\"No User data found to Visualize\")\n",
    "\n",
    "        with tab2:  # when switched for 2nd Tab\n",
    "            xx = st.selectbox(\"Select STATE\", state_list, key='sb2')  # let user to select state from list of states\n",
    "            district_query = f\"SELECT DISTINCT District FROM phonepe.top_trans_dist WHERE State='{xx}' AND Year= '{year}' AND Quarter ='{quarter}';\"\n",
    "            district_df = pd.read_sql(district_query, con=mycon)\n",
    "            district_list = district_df['District'].tolist()  # returns a list of district in selected state\n",
    "            dist_trans_val = []  # creating a empty list to store transaction value of respective district\n",
    "            for k in district_list:\n",
    "                dist_trans_query = f\"SELECT DISTINCT * FROM phonepe.top_trans_dist WHERE State = '{xx}' AND Year = '{year}' AND Quarter ='{quarter}' AND District = '{k}';\"\n",
    "                dist_trans_df = pd.read_sql(dist_trans_query, con=mycon)\n",
    "                dist_trans_list = dist_trans_df.values.tolist()\n",
    "                dist_trans_val.append(dist_trans_list[0][5] if len(\n",
    "                    dist_trans_list) != 0 else 0)  # returns transaction value of respective district\n",
    "            dist_user_val = []  # creating a empty list to store user count of respective district\n",
    "            for l in district_list:\n",
    "                dist_user_query = f\"SELECT DISTINCT * FROM phonepe.top_user_dis WHERE State = '{xx}' AND Year = '{year}' AND Quarter ='{quarter}' AND District = '{l}';\"\n",
    "                dist_user_df = pd.read_sql(dist_user_query, con=mycon)\n",
    "                dist_user_list = dist_user_df.values.tolist()\n",
    "                dist_user_val.append(dist_user_list[0][4] if len(\n",
    "                    dist_user_list) != 0 else 0)  # returns a list of user count of respective district\n",
    "\n",
    "            col3, col4 = st.columns(2)  # diving the page into two equal sections\n",
    "            with col3:  # with first half section\n",
    "                # block of code to create a bar chart\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                plt.bar(district_list, dist_trans_val, color=\"blue\")\n",
    "                plt.xticks(rotation=90)\n",
    "                plt.xlabel('District')\n",
    "                plt.ylabel('TransAmount')\n",
    "                plt.title('DistrictWise Transaction Analysis')\n",
    "                # ax = plt.axes()\n",
    "                for i, j in zip(district_list, dist_trans_val):\n",
    "                    plt.annotate(str(int(j)),\n",
    "                                 xy=(i, j + 3),\n",
    "                                 color='black',\n",
    "                                 size='7')\n",
    "                st.pyplot(plt)\n",
    "            with col4:  # with second half section\n",
    "                # block of code to create a bar chart\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                plt.bar(district_list, dist_user_val, color=\"blue\")\n",
    "                plt.xticks(rotation=90)\n",
    "                plt.xlabel('District')\n",
    "                plt.ylabel('UserCount')\n",
    "                plt.title('DistrictWise User Analysis')\n",
    "                for i, j in zip(district_list, dist_user_val):\n",
    "                    plt.annotate(str(int(j)),\n",
    "                                 xy=(i, j + 3),\n",
    "                                 color='black',\n",
    "                                 size='7')\n",
    "                st.pyplot(plt)\n",
    "\n",
    "        with tab3:  # when switched for 3rd Tab\n",
    "            x = st.selectbox(\"Select STATE\", state_list, key='sb3')  # let user to select state from list of states\n",
    "            pincode_trans_query = f\"SELECT DISTINCT Pincode FROM phonepe.top_trans_pin WHERE State='{x}' AND Year= '{year}' AND Quarter ='{quarter}';\"\n",
    "            pincode_trans_df = pd.read_sql(pincode_trans_query, con=mycon)\n",
    "            pincode_trans_list = pincode_trans_df[\n",
    "                'Pincode'].tolist()  # returns a list of pincode where transaction data available\n",
    "            pincode_user_query = f\"SELECT DISTINCT Pincode FROM phonepe.top_user_pin WHERE State='{x}' AND Year= '{year}' AND Quarter ='{quarter}';\"\n",
    "            pincode_user_df = pd.read_sql(pincode_user_query, con=mycon)\n",
    "            pincode_user_list = pincode_user_df['Pincode'].tolist()  # returns a list of pincode where user data available\n",
    "            pincode_trans_val = []  # creating an empty list to store the pincodewise transaction data\n",
    "            for k in pincode_trans_list:\n",
    "                pin_trans_query = f\"SELECT DISTINCT * FROM phonepe.top_trans_pin WHERE State = '{x}' AND Year = '{year}' AND Quarter ='{quarter}' AND Pincode = '{k}';\"\n",
    "                pin_trans_df = pd.read_sql(pin_trans_query, con=mycon)\n",
    "                pin_trans_list = pin_trans_df.values.tolist()\n",
    "                pincode_trans_val.append(pin_trans_list[0][5] if len(\n",
    "                    pin_trans_list) != 0 else 0)  # returns a list of pincodewise transaction data\n",
    "            pincode_user_val = []  # creating an empty list to store the pincodewise user data\n",
    "            for l in pincode_user_list:\n",
    "                pin_user_query = f\"SELECT DISTINCT * FROM phonepe.top_user_pin WHERE State = '{x}' AND Year = '{year}' AND Quarter ='{quarter}' AND Pincode = '{l}';\"\n",
    "                pin_user_df = pd.read_sql(pin_user_query, con=mycon)\n",
    "                pin_user_list = pin_user_df.values.tolist()\n",
    "                pincode_user_val.append(\n",
    "                    pin_user_list[0][4] if len(pin_user_list) != 0 else 0)  # returns a list of pincodewise user data\n",
    "\n",
    "            col5, col6 = st.columns(2)  # diving the page into two equal sections\n",
    "            with col5:  # with first half section\n",
    "                # block of code to consrtuct the bar chart\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                plt.bar(pincode_trans_list, pincode_trans_val, color=\"blue\")\n",
    "                plt.xticks(rotation=90)\n",
    "                plt.xlabel('PINCODE')\n",
    "                plt.ylabel('TransAmount')\n",
    "                plt.title('PINCODEWise Transaction Analysis')\n",
    "                # ax = plt.axes()\n",
    "                for i, j in zip(pincode_trans_list, pincode_trans_val):\n",
    "                    plt.annotate(str(int(j)),\n",
    "                                 xy=(i, j + 3),\n",
    "                                 color='black',\n",
    "                                 size='7')\n",
    "                st.pyplot(plt)\n",
    "            with col6:  # with second half section\n",
    "                # block of code to consrtuct the bar chart\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                plt.bar(pincode_user_list, pincode_user_val, color=\"blue\")\n",
    "                plt.xticks(rotation=90)\n",
    "                plt.xlabel('PINCODE')\n",
    "                plt.ylabel('UserCount')\n",
    "                plt.title('PINCODEWise User Analysis')\n",
    "                for i, j in zip(pincode_user_list, pincode_user_val):\n",
    "                    plt.annotate(str(int(j)),\n",
    "                                 xy=(i, j + 3),\n",
    "                                 color='black',\n",
    "                                 size='7')\n",
    "                st.pyplot(plt)\n",
    "\n",
    "        with tab4:  # when switched for 4th Tab\n",
    "            type_query = f\"SELECT DISTINCT Transaction_type FROM phonepe.agg_trans\"\n",
    "            type_df = pd.read_sql(type_query, con=mycon)\n",
    "            type_list = type_df['Transaction_type'].tolist()\n",
    "            x = st.selectbox(\"Select Type of Transaction\",\n",
    "                             type_list)  # let user to select Type of transaction from list of transaction types\n",
    "            type_trans_val = []  # creates an empty list to store typewise trans amount\n",
    "            for ii in state_list:\n",
    "                type_trans_query = f\"SELECT DISTINCT * FROM phonepe.agg_trans WHERE State='{ii}' AND Year = '{year}' AND Quarter ='{quarter}' AND Transaction_type = '{x}';\"\n",
    "                type_trans_df = pd.read_sql(type_trans_query, con=mycon)\n",
    "                type_trans_list = type_trans_df.values.tolist()\n",
    "                type_trans_val.append(\n",
    "                    type_trans_list[0][5] if len(type_trans_list) != 0 else 0)  # returns a list of typewise trans amount\n",
    "            type_trans_count = []  # creates an empty list to store typewise trans count\n",
    "            for ii in state_list:\n",
    "                type_trans_query = f\"SELECT DISTINCT * FROM phonepe.agg_trans WHERE State='{ii}' AND Year = '{year}' AND Quarter ='{quarter}' AND Transaction_type = '{x}';\"\n",
    "                type_trans_df = pd.read_sql(type_trans_query, con=mycon)\n",
    "                type_trans_list = type_trans_df.values.tolist()\n",
    "                type_trans_count.append(\n",
    "                    type_trans_list[0][4] if len(type_trans_list) != 0 else 0)  # returns a list of typewise trans count\n",
    "            col7, col8 = st.columns(2)  # diving the page into two equal sections\n",
    "            with col7:  # with first half section\n",
    "                # block of code to consrtuct the bar chart\n",
    "                plt.figure(figsize=(20, 10))\n",
    "                ax = plt.axes()\n",
    "                ax.set_facecolor('black')\n",
    "                ax.grid(linewidth=0.4, color='#8f8f8f')\n",
    "                plt.xticks(rotation='vertical', size='20', color='green')\n",
    "                plt.yticks(size='20', color='red')\n",
    "                ax.set_xlabel('\\nStates', size=25, color='brown')\n",
    "                ax.set_ylabel('Transaction Count\\n', size=25, color='brown')\n",
    "                plt.tick_params(size=20, color='white')\n",
    "                ax.set_title('Category wise breakdown of Transaction Count\\n', size=50, color='violet')\n",
    "                plt.bar(state_list, type_trans_count, label='re')\n",
    "                for i, j in zip(state_list, type_trans_count):\n",
    "                    ax.annotate(str(int(j)),\n",
    "                                xy=(i, j + 3),\n",
    "                                color='white',\n",
    "                                size='15')\n",
    "                st.pyplot(plt)\n",
    "            with col8:  # with second half section\n",
    "                # block of code to consrtuct the bar chart\n",
    "                plt.figure(figsize=(20, 10))\n",
    "                ax = plt.axes()\n",
    "                ax.set_facecolor('black')\n",
    "                ax.grid(linewidth=0.4, color='#8f8f8f')\n",
    "                plt.xticks(rotation='vertical', size='20', color='green')\n",
    "                plt.yticks(size='20', color='red')\n",
    "                ax.set_xlabel('\\nStates', size=25, color='brown')\n",
    "                ax.set_ylabel('Transaction Value\\n', size=25, color='brown')\n",
    "                plt.tick_params(size=20, color='white')\n",
    "                ax.set_title('Category wise breakdown of Transaction Value\\n', size=50, color='violet')\n",
    "                plt.bar(state_list, type_trans_val, label='re')\n",
    "                for i, j in zip(state_list, type_trans_val):\n",
    "                    ax.annotate(str(int(j)),\n",
    "                                xy=(i, j + 3),\n",
    "                                color='white',\n",
    "                                size='15')\n",
    "                st.pyplot(plt)\n",
    "\n",
    "        with tab5:  # when switched for 5th Tab\n",
    "            maps = st.selectbox(\"Select Option\", ['NationWide Transaction Analysis',\n",
    "                                                  'NationWide User Analysis'])  # let the user select from list\n",
    "            if maps == 'NationWide Transaction Analysis':\n",
    "                # loading json file that consits of india geological data\n",
    "                india_states = json.load(open(\"D:\\DOWNLOADS\\states_india.geojson\", \"r\"))\n",
    "                state_id_map = {}\n",
    "                # assigning key value to access\n",
    "                for feature in india_states[\"features\"]:\n",
    "                    feature[\"id\"] = feature[\"properties\"][\"state_code\"]\n",
    "                    state_id_map[feature[\"properties\"][\"st_nm\"]] = feature[\"id\"]\n",
    "                # creating a dict file to store data required for visualization\n",
    "                state_data = {'State': state_list,\n",
    "                              \"Total_Amount\": []}\n",
    "                for i in state_list:\n",
    "                    total_trans_query = f\"SELECT SUM(Transaction_amount) as NET_AMOUNT FROM phonepe.agg_trans WHERE State='{i}' AND Year = '{year}' AND Quarter ='{quarter}';\"\n",
    "                    total_trans_df = pd.read_sql(total_trans_query, con=mycon)\n",
    "                    total_trans_list = total_trans_df.values.tolist()\n",
    "                    state_data['Total_Amount'].append(total_trans_list[0][0] if len(\n",
    "                        total_trans_list) != 0 else 0)  # returns cumulative Transaction Amount of respective state\n",
    "\n",
    "                state_df = pd.DataFrame(state_data)  # converting dict to dataframe\n",
    "\n",
    "                state_df[\"State\"] = state_df[\"State\"].str.capitalize()  # formatting state name to match as per GeoJson\n",
    "\n",
    "                state_name_mapping = {'Arunachal-pradesh': 'Arunanchal-Pradesh',\n",
    "                                      'Dadra-&-nagar-haveli-&-daman-&-diu': 'Dadara & Nagar Havelli',\n",
    "                                      'Delhi': 'NCT of Delhi',\n",
    "                                      'Andaman-&-nicobar-islands': 'Andaman & Nicobar Island',\n",
    "                                      'Andhra-pradesh': 'Andhra Pradesh',\n",
    "                                      'Himachal-pradesh': 'Himachal Pradesh',\n",
    "                                      'Jammu-&-kashmir': \"Jammu & Kashmir\",\n",
    "                                      'Madhya-pradesh': 'Madhya Pradesh',\n",
    "                                      'Tamil-nadu': 'Tamil Nadu',\n",
    "                                      'Uttar-pradesh': 'Uttar Pradesh',\n",
    "                                      'West-bengal': 'West Bengal'\n",
    "                                      }\n",
    "                state_df['State'] = state_df['State'].replace(state_name_mapping,\n",
    "                                                              regex=True)  # formatting state name to match as per GeoJson\n",
    "                condition_to_delete = state_df['State'] == 'Ladakh'\n",
    "                state_df = state_df[\n",
    "                    ~condition_to_delete]  # deleting ladakh from dataframe as GeoJson doesn't contain ladakh to avoid error\n",
    "                state_df[\"State\"] = state_df[\"State\"].apply(\n",
    "                    lambda x: x.replace(\"-\", \" \"))  # formatting state name to match as per GeoJson\n",
    "                state_df[\"id\"] = state_df[\"State\"].apply(\n",
    "                    lambda x: state_id_map[x])  # accessing with key value to access GeoJson\n",
    "\n",
    "                state_df[\"TransactionScale\"] = np.log10(state_df[\"Total_Amount\"])  # defining a color scale\n",
    "                # block of code to construct map\n",
    "                fig = px.choropleth_mapbox(\n",
    "                    state_df,\n",
    "                    locations=\"id\",\n",
    "                    geojson=india_states,\n",
    "                    color=\"TransactionScale\",\n",
    "                    hover_name=\"State\",\n",
    "                    hover_data=[\"Total_Amount\"],\n",
    "                    title=\"India Population Density\",\n",
    "                    mapbox_style=\"carto-positron\",\n",
    "                    center={\"lat\": 24, \"lon\": 78},\n",
    "                    zoom=3,\n",
    "                    opacity=0.5\n",
    "                )\n",
    "\n",
    "                st.plotly_chart(fig, use_container_width=True, help='Sample text')\n",
    "\n",
    "            if maps == 'NationWide User Analysis':\n",
    "                # loading json file that consits of india geological data\n",
    "                india_states = json.load(open(\"D:\\DOWNLOADS\\states_india.geojson\", \"r\"))\n",
    "                state_id_map = {}\n",
    "                # assigning key value to access\n",
    "                for feature in india_states[\"features\"]:\n",
    "                    feature[\"id\"] = feature[\"properties\"][\"state_code\"]\n",
    "                    state_id_map[feature[\"properties\"][\"st_nm\"]] = feature[\"id\"]\n",
    "                # creating a dict file to store data required for visualization\n",
    "                state_user_data = {'State': state_list,\n",
    "                                   \"Total_Users\": []}\n",
    "                for i in state_list:\n",
    "                    total_user_query = f\"SELECT Registered_Users FROM phonepe.agg_user WHERE State='{i}' AND Year = '{year}' AND Quarter ='{quarter}';\"\n",
    "                    total_user_df = pd.read_sql(total_user_query, con=mycon)\n",
    "                    total_user_list = total_user_df.values.tolist()\n",
    "                    state_user_data['Total_Users'].append(total_user_list[0][0] if len(\n",
    "                        total_user_list) != 0 else 0)  # returns cumulative users of respective state\n",
    "\n",
    "                state_user_df = pd.DataFrame(state_user_data)  # converting dict to dataframe\n",
    "\n",
    "                state_user_df[\"State\"] = state_user_df[\n",
    "                    \"State\"].str.capitalize()  # formatting state name to match as per GeoJson\n",
    "\n",
    "                state_name_mapping = {'Arunachal-pradesh': 'Arunanchal-Pradesh',\n",
    "                                      'Dadra-&-nagar-haveli-&-daman-&-diu': 'Dadara & Nagar Havelli',\n",
    "                                      'Delhi': 'NCT of Delhi',\n",
    "                                      'Andaman-&-nicobar-islands': 'Andaman & Nicobar Island',\n",
    "                                      'Andhra-pradesh': 'Andhra Pradesh',\n",
    "                                      'Himachal-pradesh': 'Himachal Pradesh',\n",
    "                                      'Jammu-&-kashmir': \"Jammu & Kashmir\",\n",
    "                                      'Madhya-pradesh': 'Madhya Pradesh',\n",
    "                                      'Tamil-nadu': 'Tamil Nadu',\n",
    "                                      'Uttar-pradesh': 'Uttar Pradesh',\n",
    "                                      'West-bengal': 'West Bengal'\n",
    "                                      }\n",
    "                state_user_df['State'] = state_user_df['State'].replace(state_name_mapping,\n",
    "                                                                        regex=True)  # formatting state name to match as per GeoJson\n",
    "                condition_to_delete = state_user_df['State'] == 'Ladakh'\n",
    "                state_user_df = state_user_df[\n",
    "                    ~condition_to_delete]  # deleting ladakh from dataframe as GeoJson doesn't contain ladakh to avoid error\n",
    "                state_user_df[\"State\"] = state_user_df[\"State\"].apply(\n",
    "                    lambda x: x.replace(\"-\", \" \"))  # formatting state name to match as per GeoJson\n",
    "                state_user_df[\"id\"] = state_user_df[\"State\"].apply(\n",
    "                    lambda x: state_id_map[x])  # accessing with key value to access GeoJson\n",
    "\n",
    "                state_user_df[\"TransactionScale\"] = np.log10(state_user_df[\"Total_Users\"])  # defining a color scale\n",
    "                # block of code to construct map\n",
    "                fig = px.choropleth_mapbox(\n",
    "                    state_user_df,\n",
    "                    locations=\"id\",\n",
    "                    geojson=india_states,\n",
    "                    color=\"TransactionScale\",\n",
    "                    hover_name=\"State\",\n",
    "                    hover_data=[\"Total_Users\"],\n",
    "                    title=\"India Population Density\",\n",
    "                    mapbox_style=\"carto-positron\",\n",
    "                    center={\"lat\": 24, \"lon\": 78},\n",
    "                    zoom=3,\n",
    "                    opacity=0.5\n",
    "                )\n",
    "\n",
    "                st.plotly_chart(fig, use_container_width=True, help='Sample text')\n",
    "\n",
    "elif nav=='About Page':#display the data of Author\n",
    "    st.title(\":dart: About Page\")\n",
    "    st.subheader(\"**Crafted by :**\")\n",
    "    st.markdown(\"#### _ROHITH VIGNESH CS_\")\n",
    "    st.markdown(\"### Linked In\")\n",
    "    st.info(\"https://www.linkedin.com/in/csrv547/\")\n",
    "    st.markdown(\"### GITHUB Profile\")\n",
    "    st.info(\"https://github.com/CSRV547\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
